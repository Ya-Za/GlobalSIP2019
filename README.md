# Dynamic Sparse Encoding Models for Modeling High-dimensional Data Resulting From the Interaction of Sensory and Cognitive Factors

This paper aims to develop a statistical framework that incorporates the complex interactions between non-sensory covariates, here a saccadic eye movement, and sensory covariates, which dynamically alter the relationship between the stimulus and the neural response on fast timescales. We characterize the time-varying temporal sensitivity of a neuron at each spatial location in the visual field using a high-resolution, discretized representation of time and space dimensions. We then identify the precise time and space segments where the presence of a visual stimulus there affects the response of a neuron. This process reduced the dimensionality of the stimulus-response relationship by orders of magnitude and enabled us to trace the neuronâ€™s changing spatiotemporal receptive fields, with precision on the order of milliseconds relative to the saccade time. We validate our model by testing its ability to reproduce the perisaccadic response modulations of neurons in the middle temporal and V4 areas in macaque monkeys during a visually guided saccade task using a high spatiotemporal resolution visual stimulation paradigm. Such dynamic, sparse encoding models estimated in a statistically optimal framework provides a powerful platform for understanding how high-dimensional computations at the interaction of sensory and cognitive factors lead to the brain's complex dynamic, robust functions such as our visual perception across eye movements. Using the decoding aspect of these dynamic, sparse encoding models, can in turn advance existing decoding algorithms for neural prostheses to be able to capture and dissociate the effect of cognitive factors in sensory or motor responses and therefore to operate robustly by discarding the irrelevant information to the decoding task in hand.
